# TinyLM

Implementation of Language Models from Scratch for Self-Educational Purposes

## About

TinyLM is a set of language model implementation from scratch for self-educational purposes, and focuses on:

- Running small language models on single GPU
- Modern language model inference architectures
  - [ ] Key-value caching
  - [ ] Optimized execution
    - [ ] `torch.compile`
    - [ ] FlashInfer
  - [ ] Dynamic batching
