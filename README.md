# TinyLM

Implementation of Language Models from Scratch for Self-Educational Purposes

## About

TinyLM is a set of language model implementation from scratch for self-educational purposes, and focuses on:

- Running small language models on single GPU
- Modern language model inference architectures
  * Efficient key-value caching such as PagedAttention and RadixAttention
  * Optimized kernels such as FlashAttention and FlashInfer
  * Efficient batching and scheduling such as Nanoflow
